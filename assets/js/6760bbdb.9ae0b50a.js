"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7308],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),d=i,g=u["".concat(l,".").concat(d)]||u[d]||m[d]||o;return n?a.createElement(g,r(r({ref:t},p),{},{components:n})):a.createElement(g,r({ref:t},p))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var o=n.length,r=new Array(o);r[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var c=2;c<o;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},49547:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return l},default:function(){return d},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return m}});var a=n(87462),i=n(63366),o=(n(67294),n(3905)),r=["components"],s={},l="Image Segmentation",c={unversionedId:"concepts/vision/image-segmentation",id:"concepts/vision/image-segmentation",title:"Image Segmentation",description:"/img/content-concepts-raw-computer-vision-image-segmentation-slide46.png",source:"@site/docs/03-concepts/vision/image-segmentation.mdx",sourceDirName:"03-concepts/vision",slug:"/concepts/vision/image-segmentation",permalink:"/ai-kb/docs/concepts/vision/image-segmentation",editUrl:"https://github.com/sparsh-ai/ai-kb/docs/03-concepts/vision/image-segmentation.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Facial Analytics",permalink:"/ai-kb/docs/concepts/vision/facial-analytics"},next:{title:"Image Similarity",permalink:"/ai-kb/docs/concepts/vision/image-similarity"}},p={},m=[{value:"Introduction",id:"introduction",level:2},{value:"Models",id:"models",level:2},{value:"U-Net",id:"u-net",level:3},{value:"Mask R-CNN",id:"mask-r-cnn",level:3},{value:"DeepLabV3+",id:"deeplabv3",level:3},{value:"Process flow",id:"process-flow",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Satellite Image Segmentation for Agricultural Fields",id:"satellite-image-segmentation-for-agricultural-fields",level:3},{value:"Detectron2 Fine-tuning",id:"detectron2-fine-tuning",level:3},{value:"Industrial Use Cases for Image Segmentation",id:"industrial-use-cases-for-image-segmentation",level:3},{value:"Real-time segmentation on Videos",id:"real-time-segmentation-on-videos",level:3},{value:"Image Segmentation Exercises",id:"image-segmentation-exercises",level:3},{value:"TorchVision Inference Experiments",id:"torchvision-inference-experiments",level:3}],u={toc:m};function d(e){var t=e.components,s=(0,i.Z)(e,r);return(0,o.kt)("wrapper",(0,a.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"image-segmentation"},"Image Segmentation"),(0,o.kt)("p",null,(0,o.kt)("img",{loading:"lazy",alt:"/img/content-concepts-raw-computer-vision-image-segmentation-slide46.png",src:n(74957).Z,width:"960",height:"720"})),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Definition:")," Image segmentation is the task of assigning labels to each pixel of an image."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Applications:")," Medical imaging, self-driving cars, satellite imaging"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Scope:")," Semantic and Instance masks, 2D pixel-mask, Real-time"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Tools:")," Detectron2, TFHub, TorchVision, DeepLab")),(0,o.kt)("h2",{id:"models"},"Models"),(0,o.kt)("h3",{id:"u-net"},"U-Net"),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},(0,o.kt)("a",{parentName:"em",href:"https://arxiv.org/abs/1505.04597"},"U-Net: Convolutional Networks for Biomedical Image Segmentation. arXiv, 2015."))),(0,o.kt)("p",null,"It was originally designed to perform medical image segmentation but it works well on a wide variety of tasks, from segmenting cells on microscope images to detecting ships or houses on photos taken from satellites."),(0,o.kt)("h3",{id:"mask-r-cnn"},"Mask R-CNN"),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},(0,o.kt)("a",{parentName:"em",href:"https://arxiv.org/abs/1703.06870"},"Mask R-CNN. arXiv, 2017."))),(0,o.kt)("p",null,"The Mask R-CNN framework is built on top of Faster R-CNN. ****So, for a given image, Mask R-CNN, in addition to the class label and bounding box coordinates for each object, will also return the object mask."),(0,o.kt)("h3",{id:"deeplabv3"},"DeepLabV3+"),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},(0,o.kt)("a",{parentName:"em",href:"https://arxiv.org/abs/1802.02611"},"Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation. arXiv, 2018."))),(0,o.kt)("p",null,"It achieves a mean IOU score of 89% on the PASCAL VOC 2012 dataset."),(0,o.kt)("h2",{id:"process-flow"},"Process flow"),(0,o.kt)("p",null,"Step 1: Collect Images"),(0,o.kt)("p",null,"Capture via camera, scrap from the internet or use public datasets"),(0,o.kt)("p",null,"Step 2: Create Labels"),(0,o.kt)("p",null,"This step is required only if the object category is not available in any pre-trained model or labels are not freely available on the web. To create the labels (pixel masks) using either open-source tools like Labelme or any other professional tool"),(0,o.kt)("p",null,"Step 3: Data Acquisition"),(0,o.kt)("p",null,"Setup the database connection and fetch the data into python environment"),(0,o.kt)("p",null,"Step 4: Data Exploration"),(0,o.kt)("p",null,"Explore the data, validate it and create preprocessing strategy"),(0,o.kt)("p",null,"Step 5: Data Preparation"),(0,o.kt)("p",null,"Clean the data and make it ready for modeling"),(0,o.kt)("p",null,"Step 6: Model Building"),(0,o.kt)("p",null,"Create the model architecture in python and perform a sanity check"),(0,o.kt)("p",null,"Step 7: Model Training"),(0,o.kt)("p",null,"Start the training process and track the progress and experiments"),(0,o.kt)("p",null,"Step 8: Model Validation"),(0,o.kt)("p",null,"Validate the final set of models and select/assemble the final model"),(0,o.kt)("p",null,"Step 9: UAT Testing"),(0,o.kt)("p",null,"Wrap the model inference engine in API for client testing"),(0,o.kt)("p",null,"Step 10: Deployment"),(0,o.kt)("p",null,"Deploy the model on cloud or edge as per the requirement"),(0,o.kt)("p",null,"Step 11: Documentation"),(0,o.kt)("p",null,"Prepare the documentation and transfer all assets to the client  "),(0,o.kt)("h2",{id:"use-cases"},"Use Cases"),(0,o.kt)("h3",{id:"satellite-image-segmentation-for-agricultural-fields"},"Satellite Image Segmentation for Agricultural Fields"),(0,o.kt)("p",null,"An image with 1800 x 1135 resolution and 60 channels. Every Month 5 bands images were shot from agricultural land for 12 months. There is 8 type of croplands. Task is to classify all unknown label pixels into one of these 8 categories. U-Net model was trained from scratch on patches. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/F991454-Satellite-Image-Segmentation-for-Agricultural-Fields-9914b549617746578c509e0382deb211"},"this")," notion."),(0,o.kt)("h3",{id:"detectron2-fine-tuning"},"Detectron2 Fine-tuning"),(0,o.kt)("p",null,"Fine-tune Detectron2 Mask R-CNN (with PointRend) model on new classes. It supports semantic, instance, and panoptic segmentation. We fine-tuned on balloons, chipsets, and faces. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/Detectron-2-D281D-bb7f769860fa434d923feef3a99f9cbb"},"this")," notion."),(0,o.kt)("h3",{id:"industrial-use-cases-for-image-segmentation"},"Industrial Use Cases for Image Segmentation"),(0,o.kt)("p",null,"Experimented with 3 industrial use cases - Carvana Vehicle Image Masking, Airbus Ship Detection, and Severstal Steel Defect Detection. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/Kaggle-Image-Segmentation-Experiments-770728c2ef9a493da20863789b112d78"},"this")," notion."),(0,o.kt)("h3",{id:"real-time-segmentation-on-videos"},"Real-time segmentation on Videos"),(0,o.kt)("p",null,"Real-time tracking and segmentation with SiamMask, semantic segmentation with LightNet++ and instance segmentation with YOLACT. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/Image-Segmentation-Inference-Experiments-26fac32c220f419a902121129b2924db"},"this")," notion."),(0,o.kt)("h3",{id:"image-segmentation-exercises"},"Image Segmentation Exercises"),(0,o.kt)("p",null,"Thresholding with Otsu and Riddler\u2013Calvard, Image segmentation with self-organizing maps, Random Walk segmentation with scikit-image, Skin color segmentation with the GMM\u2013EM algorithm, Medical image segmentation, Deep semantic segmentation, Deep instance segmentation. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/Image-Segmentation-Exercises-cc3262c55d374fb684362f5d333fb91a"},"this")," notion."),(0,o.kt)("h3",{id:"torchvision-inference-experiments"},"TorchVision Inference Experiments"),(0,o.kt)("p",null,"FCN-ResNet and DeepLabV3 (both are available in TorchVision library) inference. Available as a streamlit app. Checkout ",(0,o.kt)("a",{parentName:"p",href:"https://www.notion.so/FCN-ResNet-vs-DeepLab-App-FF841-5168fac2ed0b42b1ad95a0b9e8b26d53"},"this")," notion."))}d.isMDXComponent=!0},74957:function(e,t,n){t.Z=n.p+"assets/images/content-concepts-raw-computer-vision-image-segmentation-slide46-331f63e067964c0c76d6e8073578e9f1.png"}}]);