"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[106],{3905:function(t,e,a){a.d(e,{Zo:function(){return m},kt:function(){return u}});var n=a(67294);function l(t,e,a){return e in t?Object.defineProperty(t,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):t[e]=a,t}function s(t,e){var a=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),a.push.apply(a,n)}return a}function r(t){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?s(Object(a),!0).forEach((function(e){l(t,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(a,e))}))}return t}function o(t,e){if(null==t)return{};var a,n,l=function(t,e){if(null==t)return{};var a,n,l={},s=Object.keys(t);for(n=0;n<s.length;n++)a=s[n],e.indexOf(a)>=0||(l[a]=t[a]);return l}(t,e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(t);for(n=0;n<s.length;n++)a=s[n],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(t,a)&&(l[a]=t[a])}return l}var p=n.createContext({}),_=function(t){var e=n.useContext(p),a=e;return t&&(a="function"==typeof t?t(e):r(r({},e),t)),a},m=function(t){var e=_(t.components);return n.createElement(p.Provider,{value:e},t.children)},i={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},d=n.forwardRef((function(t,e){var a=t.components,l=t.mdxType,s=t.originalType,p=t.parentName,m=o(t,["components","mdxType","originalType","parentName"]),d=_(a),u=l,c=d["".concat(p,".").concat(u)]||d[u]||i[u]||s;return a?n.createElement(c,r(r({ref:e},m),{},{components:a})):n.createElement(c,r({ref:e},m))}));function u(t,e){var a=arguments,l=e&&e.mdxType;if("string"==typeof t||l){var s=a.length,r=new Array(s);r[0]=d;var o={};for(var p in e)hasOwnProperty.call(e,p)&&(o[p]=e[p]);o.originalType=t,o.mdxType="string"==typeof t?t:l,r[1]=o;for(var _=2;_<s;_++)r[_]=a[_];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},33835:function(t,e,a){a.r(e),a.d(e,{assets:function(){return m},contentTitle:function(){return p},default:function(){return u},frontMatter:function(){return o},metadata:function(){return _},toc:function(){return i}});var n=a(87462),l=a(63366),s=(a(67294),a(3905)),r=["components"],o={},p="Resale Price Prediction",_={unversionedId:"tutorials/resale-price-prediction",id:"tutorials/resale-price-prediction",title:"Resale Price Prediction",description:"|   | BRAND | PARTNO           | QUANTITY | UNITRESALE | UNITCOST |",source:"@site/docs/04-tutorials/resale-price-prediction.mdx",sourceDirName:"04-tutorials",slug:"/tutorials/resale-price-prediction",permalink:"/ai-kb/docs/tutorials/resale-price-prediction",editUrl:"https://github.com/sparsh-ai/ai-kb/docs/04-tutorials/resale-price-prediction.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Regression",permalink:"/ai-kb/docs/tutorials/regression"},next:{title:"Text Cleaning",permalink:"/ai-kb/docs/tutorials/text-cleaning"}},m={},i=[],d={toc:i};function u(t){var e=t.components,a=(0,l.Z)(t,r);return(0,s.kt)("wrapper",(0,n.Z)({},d,a,{components:e,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"resale-price-prediction"},"Resale Price Prediction"),(0,s.kt)("a",{href:"https://nbviewer.org/github/recohut/notebook/blob/master/_notebooks/2022-01-06-resale-prediction.ipynb",alt:""}," ",(0,s.kt)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg"})),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"# import the libraries\nimport re\nimport scipy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import coo_matrix, hstack\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom keras import backend as K\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.models import Model\n\nfrom utils import *\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.style.use('fivethirtyeight')\nplt.style.use('seaborn-notebook')\n\n%config InlineBackend.figure_format = 'retina'\n%reload_ext autoreload\n%autoreload 2\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"df = pd.read_pickle('./data/df_cleaned.p')\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"colname_map = {'PRC':'BRAND', 'PARTNO':'PARTNO','UNIT RESALE':'UNITRESALE',\n               'ORIG ORDER QTY':'ORDERQTY', 'NEW UNIT COST':'UNITCOST'}\ndf = prepare_data(df, colname_map)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"df.head()\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null}),(0,s.kt)("th",{parentName:"tr",align:null},"BRAND"),(0,s.kt)("th",{parentName:"tr",align:null},"PARTNO"),(0,s.kt)("th",{parentName:"tr",align:null},"QUANTITY"),(0,s.kt)("th",{parentName:"tr",align:null},"UNITRESALE"),(0,s.kt)("th",{parentName:"tr",align:null},"UNITCOST"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"0"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"53001176-1 REV A"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"209.66"),(0,s.kt)("td",{parentName:"tr",align:null},"107.65")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"1"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"53001176-1 REV A"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"209.66"),(0,s.kt)("td",{parentName:"tr",align:null},"99.51")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"61-82477-8"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"76.75"),(0,s.kt)("td",{parentName:"tr",align:null},"60")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"3"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA1208K08"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"66.12"),(0,s.kt)("td",{parentName:"tr",align:null},"50.8")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"4"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA1208K08X"),(0,s.kt)("td",{parentName:"tr",align:null},"50-99"),(0,s.kt)("td",{parentName:"tr",align:null},"66.21"),(0,s.kt)("td",{parentName:"tr",align:null},"52")))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"df, fitted_lambda = scale_price(df)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"df.head()\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null}),(0,s.kt)("th",{parentName:"tr",align:null},"BRAND"),(0,s.kt)("th",{parentName:"tr",align:null},"PARTNO"),(0,s.kt)("th",{parentName:"tr",align:null},"QUANTITY"),(0,s.kt)("th",{parentName:"tr",align:null},"UNITCOST"),(0,s.kt)("th",{parentName:"tr",align:null},"RESALE"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"0"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"61-82477-8"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"60"),(0,s.kt)("td",{parentName:"tr",align:null},"3.850272")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"1"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA1208K08"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"50.8"),(0,s.kt)("td",{parentName:"tr",align:null},"3.733058")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA1208K08X"),(0,s.kt)("td",{parentName:"tr",align:null},"50-99"),(0,s.kt)("td",{parentName:"tr",align:null},"52"),(0,s.kt)("td",{parentName:"tr",align:null},"3.734132")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"3"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA67006-4KA"),(0,s.kt)("td",{parentName:"tr",align:null},"50-99"),(0,s.kt)("td",{parentName:"tr",align:null},"13.9"),(0,s.kt)("td",{parentName:"tr",align:null},"2.559783")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"4"),(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"AA67006-4KA"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"13.5"),(0,s.kt)("td",{parentName:"tr",align:null},"2.686291")))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"CV1 = CountVectorizer(stop_words=None, \n                      max_df=1.0, \n                      min_df=100, \n                      ngram_range=(1,1),\n                      binary=True, \n                      analyzer='char')\n\nCV1.fit(list(set(df['PARTNO'].tolist())))\nX1 = CV1.transform(df['PARTNO'].tolist())\nX1\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<432960x45 sparse matrix of type '<class 'numpy.int64'>'\n    with 3493797 stored elements in Compressed Sparse Row format>\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"# CV1.vocabulary_\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"CV2 = CountVectorizer(stop_words=None, \n                      max_df=0.8, \n                      min_df=100, \n                      ngram_range=(2,6), \n                      binary=True,\n                      analyzer='char')\nCV2.fit(list(set(df['PARTNO'].tolist())))\nX2 = CV2.transform(df['PARTNO'].tolist())\nX2\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<432960x5430 sparse matrix of type '<class 'numpy.int64'>'\n    with 9427277 stored elements in Compressed Sparse Row format>\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"def tokenizer(text):\n  text = text.lower()\n  rx1 = r\"(?i)(?:(?<=\\d)(?=[a-z])|(?<=[a-z])(?=\\d))\"\n  text = re.sub(rx1,' ', text)\n  text = re.sub(r'[^a-z0-9]',' ', text)\n  text = ' '.join(text.split())\n  text = text.split()\n  return text\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"CV3 = TfidfVectorizer(stop_words=None, \n                      max_df=0.5, \n                      min_df=100, \n                      ngram_range=(1,5), \n                      binary=False,\n                      analyzer='word',\n                      tokenizer=tokenizer)\nCV3.fit(list(set(df['PARTNO'].tolist())))\nX3 = CV3.transform(df['PARTNO'].tolist())\nX3\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<432960x1007 sparse matrix of type '<class 'numpy.float64'>'\n    with 1715717 stored elements in Compressed Sparse Row format>\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"enc = OneHotEncoder()\nohecols = ['BRAND','QUANTITY']\nenc.fit(df[ohecols])\nX4 = enc.transform(df[ohecols])\nX4\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<432960x577 sparse matrix of type '<class 'numpy.float64'>'\n    with 865920 stored elements in Compressed Sparse Row format>\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"X = hstack([X1, X2, X3, X4])\nX\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<432960x7059 sparse matrix of type '<class 'numpy.float64'>'\n    with 15502711 stored elements in COOrdinate format>\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Y = df['RESALE'].values\nY = Y.reshape(-1,1)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=40)\nprint("Training Records {}, Testing Records: {}".format(X_train.shape[0],\n                                                        X_test.shape[0]))\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Training Records 389664, Testing Records: 43296\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"batch_size = 2048\nepochs = 75\n\ninputs = Input(shape=(X_train.shape[1],), sparse=True)\nL = Dense(512, activation='relu')(inputs)\nL = Dropout(0.5)(L)\nL = Dense(10, activation='relu')(L)\noutputs = Dense(y_train.shape[1])(L)\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(loss='mse', optimizer='adam', metrics=['mae'])\nmodel.summary()\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'Model: "functional_3"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 7059)]            0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 512)               3614720   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                5130      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 3,619,861\nTrainable params: 3,619,861\nNon-trainable params: 0\n_________________________________________________________________\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"history = model.fit(nn_batch_generator(X_train, y_train, batch_size),\n          steps_per_epoch=len(y_train)//batch_size, \n          validation_data=nn_batch_generator(X_test, y_test, batch_size),\n          validation_steps=len(y_test)//batch_size, \n          epochs=100,\n          workers=-1, \n          use_multiprocessing=True)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Epoch 1/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.8163 - mae: 0.6779 - val_loss: 0.4789 - val_mae: 0.5142\nEpoch 2/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.4670 - mae: 0.5137 - val_loss: 0.4088 - val_mae: 0.4675\nEpoch 3/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.3991 - mae: 0.4744 - val_loss: 0.3682 - val_mae: 0.4406\nEpoch 4/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.3548 - mae: 0.4472 - val_loss: 0.3426 - val_mae: 0.4222\nEpoch 5/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.3244 - mae: 0.4278 - val_loss: 0.3288 - val_mae: 0.4123\nEpoch 6/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.3011 - mae: 0.4124 - val_loss: 0.3146 - val_mae: 0.4022\nEpoch 7/100\n190/190 [==============================] - 22s 115ms/step - loss: 0.2838 - mae: 0.4004 - val_loss: 0.3066 - val_mae: 0.3963\nEpoch 8/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2701 - mae: 0.3905 - val_loss: 0.3014 - val_mae: 0.3924\nEpoch 9/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.2593 - mae: 0.3820 - val_loss: 0.2951 - val_mae: 0.3861\nEpoch 10/100\n190/190 [==============================] - 22s 115ms/step - loss: 0.2493 - mae: 0.3746 - val_loss: 0.2937 - val_mae: 0.3852\nEpoch 11/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2419 - mae: 0.3688 - val_loss: 0.2899 - val_mae: 0.3798\nEpoch 12/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.2353 - mae: 0.3633 - val_loss: 0.2867 - val_mae: 0.3771\nEpoch 13/100\n190/190 [==============================] - 22s 116ms/step - loss: 0.2279 - mae: 0.3574 - val_loss: 0.2877 - val_mae: 0.3767\nEpoch 14/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2238 - mae: 0.3538 - val_loss: 0.2823 - val_mae: 0.3730\nEpoch 15/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2196 - mae: 0.3498 - val_loss: 0.2821 - val_mae: 0.3720\nEpoch 16/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.2142 - mae: 0.3460 - val_loss: 0.2788 - val_mae: 0.3696\nEpoch 17/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.2105 - mae: 0.3426 - val_loss: 0.2801 - val_mae: 0.3698\nEpoch 18/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2072 - mae: 0.3397 - val_loss: 0.2770 - val_mae: 0.3669\nEpoch 19/100\n190/190 [==============================] - 22s 115ms/step - loss: 0.2039 - mae: 0.3369 - val_loss: 0.2790 - val_mae: 0.3690\nEpoch 20/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.2014 - mae: 0.3345 - val_loss: 0.2755 - val_mae: 0.3657\nEpoch 21/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1980 - mae: 0.3314 - val_loss: 0.2754 - val_mae: 0.3660\nEpoch 22/100\n190/190 [==============================] - 21s 108ms/step - loss: 0.1952 - mae: 0.3290 - val_loss: 0.2757 - val_mae: 0.3649\nEpoch 23/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.1933 - mae: 0.3275 - val_loss: 0.2731 - val_mae: 0.3633\nEpoch 24/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1913 - mae: 0.3254 - val_loss: 0.2734 - val_mae: 0.3632\nEpoch 25/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1880 - mae: 0.3225 - val_loss: 0.2721 - val_mae: 0.3617\nEpoch 26/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1870 - mae: 0.3213 - val_loss: 0.2732 - val_mae: 0.3626\nEpoch 27/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.1838 - mae: 0.3186 - val_loss: 0.2698 - val_mae: 0.3588\nEpoch 28/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.1823 - mae: 0.3173 - val_loss: 0.2708 - val_mae: 0.3589\nEpoch 29/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1808 - mae: 0.3155 - val_loss: 0.2712 - val_mae: 0.3599\nEpoch 30/100\n190/190 [==============================] - 19s 102ms/step - loss: 0.1790 - mae: 0.3140 - val_loss: 0.2727 - val_mae: 0.3607\nEpoch 31/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1772 - mae: 0.3126 - val_loss: 0.2698 - val_mae: 0.3588\nEpoch 32/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1756 - mae: 0.3108 - val_loss: 0.2703 - val_mae: 0.3584\nEpoch 33/100\n190/190 [==============================] - 19s 99ms/step - loss: 0.1747 - mae: 0.3099 - val_loss: 0.2693 - val_mae: 0.3575\nEpoch 34/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1733 - mae: 0.3085 - val_loss: 0.2703 - val_mae: 0.3578\nEpoch 35/100\n190/190 [==============================] - 21s 108ms/step - loss: 0.1724 - mae: 0.3077 - val_loss: 0.2704 - val_mae: 0.3583\nEpoch 36/100\n190/190 [==============================] - 19s 99ms/step - loss: 0.1706 - mae: 0.3063 - val_loss: 0.2694 - val_mae: 0.3580\nEpoch 37/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1689 - mae: 0.3045 - val_loss: 0.2687 - val_mae: 0.3573\nEpoch 38/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1678 - mae: 0.3033 - val_loss: 0.2690 - val_mae: 0.3572\nEpoch 39/100\n190/190 [==============================] - 19s 98ms/step - loss: 0.1668 - mae: 0.3023 - val_loss: 0.2698 - val_mae: 0.3578\nEpoch 40/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1655 - mae: 0.3008 - val_loss: 0.2687 - val_mae: 0.3556\nEpoch 41/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1643 - mae: 0.3001 - val_loss: 0.2702 - val_mae: 0.3569\nEpoch 42/100\n190/190 [==============================] - 19s 98ms/step - loss: 0.1637 - mae: 0.2992 - val_loss: 0.2698 - val_mae: 0.3567\nEpoch 43/100\n190/190 [==============================] - 21s 111ms/step - loss: 0.1626 - mae: 0.2980 - val_loss: 0.2703 - val_mae: 0.3570\nEpoch 44/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.1616 - mae: 0.2973 - val_loss: 0.2695 - val_mae: 0.3552\nEpoch 45/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1610 - mae: 0.2965 - val_loss: 0.2666 - val_mae: 0.3532\nEpoch 46/100\n190/190 [==============================] - 19s 101ms/step - loss: 0.1594 - mae: 0.2948 - val_loss: 0.2683 - val_mae: 0.3530\nEpoch 47/100\n190/190 [==============================] - 19s 102ms/step - loss: 0.1587 - mae: 0.2939 - val_loss: 0.2688 - val_mae: 0.3532\nEpoch 48/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1576 - mae: 0.2931 - val_loss: 0.2676 - val_mae: 0.3528\nEpoch 49/100\n190/190 [==============================] - 21s 112ms/step - loss: 0.1565 - mae: 0.2918 - val_loss: 0.2679 - val_mae: 0.3528\nEpoch 50/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1558 - mae: 0.2911 - val_loss: 0.2676 - val_mae: 0.3522\nEpoch 51/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1549 - mae: 0.2900 - val_loss: 0.2684 - val_mae: 0.3535\nEpoch 52/100\n190/190 [==============================] - 21s 108ms/step - loss: 0.1543 - mae: 0.2895 - val_loss: 0.2707 - val_mae: 0.3553\nEpoch 53/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1535 - mae: 0.2886 - val_loss: 0.2673 - val_mae: 0.3528\nEpoch 54/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1531 - mae: 0.2880 - val_loss: 0.2672 - val_mae: 0.3523\nEpoch 55/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1519 - mae: 0.2870 - val_loss: 0.2673 - val_mae: 0.3528\nEpoch 56/100\n190/190 [==============================] - 21s 109ms/step - loss: 0.1513 - mae: 0.2862 - val_loss: 0.2670 - val_mae: 0.3528\nEpoch 57/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1503 - mae: 0.2852 - val_loss: 0.2684 - val_mae: 0.3535\nEpoch 58/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1497 - mae: 0.2847 - val_loss: 0.2678 - val_mae: 0.3526\nEpoch 59/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1489 - mae: 0.2837 - val_loss: 0.2668 - val_mae: 0.3514\nEpoch 60/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1480 - mae: 0.2828 - val_loss: 0.2681 - val_mae: 0.3531\nEpoch 61/100\n190/190 [==============================] - 21s 108ms/step - loss: 0.1476 - mae: 0.2822 - val_loss: 0.2675 - val_mae: 0.3520\nEpoch 62/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1474 - mae: 0.2818 - val_loss: 0.2674 - val_mae: 0.3518\nEpoch 63/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1465 - mae: 0.2809 - val_loss: 0.2670 - val_mae: 0.3508\nEpoch 64/100\n190/190 [==============================] - 21s 108ms/step - loss: 0.1462 - mae: 0.2808 - val_loss: 0.2655 - val_mae: 0.3499\nEpoch 65/100\n190/190 [==============================] - 21s 110ms/step - loss: 0.1455 - mae: 0.2800 - val_loss: 0.2678 - val_mae: 0.3510\nEpoch 66/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1445 - mae: 0.2789 - val_loss: 0.2679 - val_mae: 0.3507\nEpoch 67/100\n190/190 [==============================] - 20s 103ms/step - loss: 0.1438 - mae: 0.2780 - val_loss: 0.2680 - val_mae: 0.3507\nEpoch 68/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1434 - mae: 0.2777 - val_loss: 0.2683 - val_mae: 0.3514\nEpoch 69/100\n190/190 [==============================] - 22s 113ms/step - loss: 0.1424 - mae: 0.2769 - val_loss: 0.2693 - val_mae: 0.3516\nEpoch 70/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1426 - mae: 0.2768 - val_loss: 0.2679 - val_mae: 0.3508\nEpoch 71/100\n190/190 [==============================] - 20s 105ms/step - loss: 0.1410 - mae: 0.2752 - val_loss: 0.2672 - val_mae: 0.3505\nEpoch 72/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.1410 - mae: 0.2749 - val_loss: 0.2663 - val_mae: 0.3493\nEpoch 73/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1404 - mae: 0.2742 - val_loss: 0.2681 - val_mae: 0.3512\nEpoch 74/100\n190/190 [==============================] - 20s 105ms/step - loss: 0.1398 - mae: 0.2738 - val_loss: 0.2666 - val_mae: 0.3490\nEpoch 75/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.1400 - mae: 0.2736 - val_loss: 0.2663 - val_mae: 0.3497\nEpoch 76/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1393 - mae: 0.2731 - val_loss: 0.2665 - val_mae: 0.3494\nEpoch 77/100\n190/190 [==============================] - 20s 105ms/step - loss: 0.1388 - mae: 0.2724 - val_loss: 0.2672 - val_mae: 0.3505\nEpoch 78/100\n190/190 [==============================] - 22s 114ms/step - loss: 0.1386 - mae: 0.2720 - val_loss: 0.2678 - val_mae: 0.3499\nEpoch 79/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1382 - mae: 0.2717 - val_loss: 0.2678 - val_mae: 0.3497\nEpoch 80/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1377 - mae: 0.2711 - val_loss: 0.2675 - val_mae: 0.3497\nEpoch 81/100\n190/190 [==============================] - 22s 113ms/step - loss: 0.1374 - mae: 0.2709 - val_loss: 0.2669 - val_mae: 0.3495\nEpoch 82/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1370 - mae: 0.2702 - val_loss: 0.2674 - val_mae: 0.3496\nEpoch 83/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1362 - mae: 0.2692 - val_loss: 0.2675 - val_mae: 0.3504\nEpoch 84/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.1358 - mae: 0.2690 - val_loss: 0.2664 - val_mae: 0.3496\nEpoch 85/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1351 - mae: 0.2681 - val_loss: 0.2692 - val_mae: 0.3511\nEpoch 86/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1352 - mae: 0.2679 - val_loss: 0.2671 - val_mae: 0.3498\nEpoch 87/100\n190/190 [==============================] - 21s 113ms/step - loss: 0.1346 - mae: 0.2675 - val_loss: 0.2687 - val_mae: 0.3503\nEpoch 88/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1343 - mae: 0.2672 - val_loss: 0.2691 - val_mae: 0.3494\nEpoch 89/100\n190/190 [==============================] - 20s 103ms/step - loss: 0.1337 - mae: 0.2667 - val_loss: 0.2687 - val_mae: 0.3503\nEpoch 90/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1335 - mae: 0.2660 - val_loss: 0.2689 - val_mae: 0.3502\nEpoch 91/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1334 - mae: 0.2659 - val_loss: 0.2686 - val_mae: 0.3494\nEpoch 92/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1331 - mae: 0.2657 - val_loss: 0.2674 - val_mae: 0.3489\nEpoch 93/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1326 - mae: 0.2649 - val_loss: 0.2664 - val_mae: 0.3486\nEpoch 94/100\n190/190 [==============================] - 20s 105ms/step - loss: 0.1320 - mae: 0.2644 - val_loss: 0.2668 - val_mae: 0.3486\nEpoch 95/100\n190/190 [==============================] - 20s 107ms/step - loss: 0.1322 - mae: 0.2645 - val_loss: 0.2683 - val_mae: 0.3494\nEpoch 96/100\n190/190 [==============================] - 20s 104ms/step - loss: 0.1313 - mae: 0.2637 - val_loss: 0.2675 - val_mae: 0.3496\nEpoch 97/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1313 - mae: 0.2636 - val_loss: 0.2666 - val_mae: 0.3485\nEpoch 98/100\n190/190 [==============================] - 20s 108ms/step - loss: 0.1309 - mae: 0.2633 - val_loss: 0.2679 - val_mae: 0.3493\nEpoch 99/100\n190/190 [==============================] - 20s 103ms/step - loss: 0.1309 - mae: 0.2629 - val_loss: 0.2670 - val_mae: 0.3487\nEpoch 100/100\n190/190 [==============================] - 20s 106ms/step - loss: 0.1301 - mae: 0.2622 - val_loss: 0.2667 - val_mae: 0.3485\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"model.save('./models/model_201203.h5')\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"hist_df = pd.DataFrame(history.history) \nhist_csv_file = './outputs/history.csv'\nwith open(hist_csv_file, mode='w') as f:\n  hist_df.to_csv(f)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"from scipy.special import inv_boxcox\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n\ny_pred = model.predict(X_test).flatten()\na = inv_boxcox(y_test.flatten(), fitted_lambda)\nb = inv_boxcox(y_pred.flatten(), fitted_lambda)\nprint('r2_score: ', r2_score(a, b))\nprint('median_absolute_error: ', median_absolute_error(a, b))\nprint('mean_absolute_error', mean_absolute_error(a, b))\nout2 = pd.DataFrame({'y_true':inv_boxcox(y_test.flatten(), fitted_lambda), 'y_pred':inv_boxcox(y_pred.flatten(), fitted_lambda)})\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"r2_score:  0.7725025811056968\nmedian_absolute_error:  0.49407594919204767\nmean_absolute_error 3.357431710265042\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"out2.head()\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null}),(0,s.kt)("th",{parentName:"tr",align:null},"y_true"),(0,s.kt)("th",{parentName:"tr",align:null},"y_pred"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"0"),(0,s.kt)("td",{parentName:"tr",align:null},"4.65"),(0,s.kt)("td",{parentName:"tr",align:null},"10.811751")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"1"),(0,s.kt)("td",{parentName:"tr",align:null},"7.6"),(0,s.kt)("td",{parentName:"tr",align:null},"7.666917")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"2"),(0,s.kt)("td",{parentName:"tr",align:null},"1.1"),(0,s.kt)("td",{parentName:"tr",align:null},"0.746361")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"3"),(0,s.kt)("td",{parentName:"tr",align:null},"0.72"),(0,s.kt)("td",{parentName:"tr",align:null},"0.291657")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"4"),(0,s.kt)("td",{parentName:"tr",align:null},"41.4"),(0,s.kt)("td",{parentName:"tr",align:null},"31.236202")))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"_, out1 = train_test_split(df, test_size=0.1, random_state=40)\nout1['RESALE'] = out2.y_true.values\nout1['PRED'] = out2.y_pred.values\nout1.to_csv('./outputs/result.csv', index=False)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"out1.sample(10)\n")),(0,s.kt)("table",null,(0,s.kt)("thead",{parentName:"table"},(0,s.kt)("tr",{parentName:"thead"},(0,s.kt)("th",{parentName:"tr",align:null}),(0,s.kt)("th",{parentName:"tr",align:null},"BRAND"),(0,s.kt)("th",{parentName:"tr",align:null},"PARTNO"),(0,s.kt)("th",{parentName:"tr",align:null},"QUANTITY"),(0,s.kt)("th",{parentName:"tr",align:null},"UNITCOST"),(0,s.kt)("th",{parentName:"tr",align:null},"RESALE"),(0,s.kt)("th",{parentName:"tr",align:null},"PRED"))),(0,s.kt)("tbody",{parentName:"table"},(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"174877"),(0,s.kt)("td",{parentName:"tr",align:null},"155"),(0,s.kt)("td",{parentName:"tr",align:null},"TLM-6X1C-12"),(0,s.kt)("td",{parentName:"tr",align:null},"2500-4999"),(0,s.kt)("td",{parentName:"tr",align:null},"0.09"),(0,s.kt)("td",{parentName:"tr",align:null},"0.15"),(0,s.kt)("td",{parentName:"tr",align:null},"0.170021")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"39616"),(0,s.kt)("td",{parentName:"tr",align:null},"59"),(0,s.kt)("td",{parentName:"tr",align:null},"MS3498-9"),(0,s.kt)("td",{parentName:"tr",align:null},"500-999"),(0,s.kt)("td",{parentName:"tr",align:null},"1.12"),(0,s.kt)("td",{parentName:"tr",align:null},"1.5"),(0,s.kt)("td",{parentName:"tr",align:null},"1.150005")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"18036"),(0,s.kt)("td",{parentName:"tr",align:null},"30"),(0,s.kt)("td",{parentName:"tr",align:null},"8106-A-0440-17"),(0,s.kt)("td",{parentName:"tr",align:null},"500-999"),(0,s.kt)("td",{parentName:"tr",align:null},"0.17"),(0,s.kt)("td",{parentName:"tr",align:null},"0.4"),(0,s.kt)("td",{parentName:"tr",align:null},"0.61341")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"406828"),(0,s.kt)("td",{parentName:"tr",align:null},"662"),(0,s.kt)("td",{parentName:"tr",align:null},"250-0201-01"),(0,s.kt)("td",{parentName:"tr",align:null},"50-99"),(0,s.kt)("td",{parentName:"tr",align:null},"3.01"),(0,s.kt)("td",{parentName:"tr",align:null},"5"),(0,s.kt)("td",{parentName:"tr",align:null},"4.733656")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"78736"),(0,s.kt)("td",{parentName:"tr",align:null},"78"),(0,s.kt)("td",{parentName:"tr",align:null},"SC-16-SB"),(0,s.kt)("td",{parentName:"tr",align:null},"05-Sep"),(0,s.kt)("td",{parentName:"tr",align:null},"59.05"),(0,s.kt)("td",{parentName:"tr",align:null},"84.35"),(0,s.kt)("td",{parentName:"tr",align:null},"91.922928")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"116973"),(0,s.kt)("td",{parentName:"tr",align:null},"116"),(0,s.kt)("td",{parentName:"tr",align:null},"NAS6206-18"),(0,s.kt)("td",{parentName:"tr",align:null},"01-Apr"),(0,s.kt)("td",{parentName:"tr",align:null},"2.18"),(0,s.kt)("td",{parentName:"tr",align:null},"25"),(0,s.kt)("td",{parentName:"tr",align:null},"24.017282")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"59365"),(0,s.kt)("td",{parentName:"tr",align:null},"63"),(0,s.kt)("td",{parentName:"tr",align:null},"MS21087-4"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"3.5"),(0,s.kt)("td",{parentName:"tr",align:null},"5.22"),(0,s.kt)("td",{parentName:"tr",align:null},"7.015954")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"256983"),(0,s.kt)("td",{parentName:"tr",align:null},"350"),(0,s.kt)("td",{parentName:"tr",align:null},"0326010.HXP"),(0,s.kt)("td",{parentName:"tr",align:null},"Oct-24"),(0,s.kt)("td",{parentName:"tr",align:null},"0.4"),(0,s.kt)("td",{parentName:"tr",align:null},"4.5"),(0,s.kt)("td",{parentName:"tr",align:null},"4.300601")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"211941"),(0,s.kt)("td",{parentName:"tr",align:null},"212"),(0,s.kt)("td",{parentName:"tr",align:null},"MS91528-1F2B"),(0,s.kt)("td",{parentName:"tr",align:null},"25-49"),(0,s.kt)("td",{parentName:"tr",align:null},"2.55"),(0,s.kt)("td",{parentName:"tr",align:null},"4.4"),(0,s.kt)("td",{parentName:"tr",align:null},"4.558315")),(0,s.kt)("tr",{parentName:"tbody"},(0,s.kt)("td",{parentName:"tr",align:null},"334493"),(0,s.kt)("td",{parentName:"tr",align:null},"525"),(0,s.kt)("td",{parentName:"tr",align:null},"M24243/1A404"),(0,s.kt)("td",{parentName:"tr",align:null},"5000-9999"),(0,s.kt)("td",{parentName:"tr",align:null},"0.12"),(0,s.kt)("td",{parentName:"tr",align:null},"0.26"),(0,s.kt)("td",{parentName:"tr",align:null},"0.203509")))))}u.isMDXComponent=!0}}]);