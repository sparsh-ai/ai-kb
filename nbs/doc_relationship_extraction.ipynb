{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Relationship Extraction\n", "\n", "In this notebook, we'll train, deploy and use an relationship extraction\n", "model using transformers from the\n", "[transformers](https://huggingface.co/transformers/) library which uses\n", "PyTorch.\n", "\n", "**Note**: When running this notebook on SageMaker Studio, you should make\n", "sure the 'SageMaker JumpStart PyTorch 1.0' image/kernel is used. When\n", "running this notebook on SageMaker Notebook Instance, you should make\n", "sure the 'sagemaker-soln' kernel is used."]}, {"cell_type": "markdown", "metadata": {}, "source": ["This solution relies on a config file to run the provisioned AWS resources. Run the cell below to generate that file."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "import os\n", "import json\n", "\n", "client = boto3.client('servicecatalog')\n", "cwd = os.getcwd().split('/')\n", "i= cwd.index('S3Downloads')\n", "pp_name = cwd[i + 1]\n", "pp = client.describe_provisioned_product(Name=pp_name)\n", "record_id = pp['ProvisionedProductDetail']['LastSuccessfulProvisioningRecordId']\n", "record = client.describe_record(Id=record_id)\n", "\n", "keys = [ x['OutputKey'] for x in record['RecordOutputs'] if 'OutputKey' and 'OutputValue' in x]\n", "values = [ x['OutputValue'] for x in record['RecordOutputs'] if 'OutputKey' and 'OutputValue' in x]\n", "stack_output = dict(zip(keys, values))\n", "\n", "with open(f'/root/S3Downloads/{pp_name}/stack_outputs.json', 'w') as f:\n", "    json.dump(stack_output, f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We start by importing a variety of packages that will be used throughout\n", "the notebook. One of the most important packages is the Amazon SageMaker\n", "Python SDK (i.e. `import sagemaker`). We also import modules from our own\n", "custom (and editable) package that can be found at `../package`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import boto3\n", "from pathlib import Path\n", "import sagemaker\n", "from sagemaker.pytorch import PyTorch\n", "import sys\n", "\n", "sys.path.insert(0, '../package')\n", "from package import config, utils"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Up next, we define the current folder and create a SageMaker client (from\n", "`boto3`). We can use the SageMaker client to call SageMaker APIs\n", "directly, as an alternative to using the Amazon SageMaker SDK. We'll use\n", "it at the end of the notebook to delete certain resources that are\n", "created in this notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["current_folder = utils.get_current_folder(globals())\n", "sagemaker_client = boto3.client('sagemaker')\n", "sagemaker_session = sagemaker.Session()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!aws s3 cp --recursive --quiet $config.SOURCE_S3_PATH/data ../data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!aws s3 cp --recursive --quiet ../data s3://$config.S3_BUCKET/$config.DATASETS_S3_PREFIX"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["hyperparameters = {\n", "    \"learning-rate\": 0.0007\n", "}\n", "\n", "current_folder = utils.get_current_folder(globals())\n", "estimator = PyTorch(\n", "    framework_version='1.5.0',\n", "    py_version='py3',\n", "    entry_point='entry_point.py',\n", "    source_dir=str(Path(current_folder, '../containers/relationship_extraction').resolve()),\n", "    hyperparameters=hyperparameters,\n", "    role=config.IAM_ROLE,\n", "    instance_count=1,\n", "    instance_type=config.TRAINING_INSTANCE_TYPE,\n", "    output_path='s3://' + str(Path(config.S3_BUCKET, config.OUTPUTS_S3_PREFIX)),\n", "    code_location='s3://' + str(Path(config.S3_BUCKET, config.OUTPUTS_S3_PREFIX)),\n", "    base_job_name=config.SOLUTION_PREFIX,\n", "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}],\n", "    sagemaker_session=sagemaker_session,\n", "    volume_size=30\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["estimator.fit({\n", "    'train': 's3://' + str(Path(config.S3_BUCKET, config.DATASETS_S3_PREFIX, 'semeval', 'train')),\n", "    'test': 's3://' + str(Path(config.S3_BUCKET, config.DATASETS_S3_PREFIX, 'semeval', 'test'))\n", "})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We'll use the unique solution prefix to name the model and endpoint."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_name = \"{}-relationship-extraction\".format(config.SOLUTION_PREFIX)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sagemaker.serializers import JSONSerializer\n", "from sagemaker.deserializers import JSONDeserializer\n", "\n", "predictor = estimator.deploy(\n", "    endpoint_name=model_name,\n", "    instance_type=config.HOSTING_INSTANCE_TYPE,\n", "    initial_instance_count=1,\n", "    serializer=JSONSerializer(),\n", "    deserializer=JSONDeserializer()\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When calling our new endpoint from the notebook, we use a Amazon\n", "SageMaker SDK\n", "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n", "A `Predictor` is used to send data to an endpoint (as part of a request),\n", "and interpret the response. Our `estimator.deploy` command returned a\n", "`Predictor` but, by default, it will send and receive numpy arrays. Our\n", "endpoint expects to receive (and also sends) JSON formatted objects, so\n", "we modify the `Predictor` to use JSON instead of the PyTorch endpoint\n", "default of numpy arrays. JSON is used here because it is a standard\n", "endpoint format and the endpoint response can contain nested data\n", "structures."]}, {"cell_type": "markdown", "metadata": {}, "source": ["With our model successfully deployed and our predictor configured, we can\n", "try out the relationship extraction model out on example inputs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictor.predict(\n", "    data={\n", "        'sequence': 'Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly.',\n", "        'entity_one_start': 0,\n", "        'entity_one_end': 6,\n", "        'entity_two_start': 7,\n", "        'entity_two_end': 16\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Clean Up\n", "\n", "When you've finished with the relationship extraction endpoint (and associated\n", "endpoint-config), make sure that you delete it to avoid accidental\n", "charges."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sagemaker_client.delete_endpoint(EndpointName=model_name)\n", "sagemaker_client.delete_endpoint_config(EndpointConfigName=model_name)"]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36", "language": "python", "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/1.8.1-cpu-py36"}}, "nbformat": 4, "nbformat_minor": 4}